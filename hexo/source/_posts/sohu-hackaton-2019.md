---
title: 搜狐黑客马拉松2019
date: 2019-04-14 13:19:45
tags: 
- 黑客马拉松
- 机器学习
categories: Competition
---

作为打酱油的角色参与了搜狐黑客马拉松2019，用一天的时间设计并实现了一个叫Trace的的产品的资讯类产品，尝试利用机器从海量文本中挖掘事件相关新闻并结合事件发生的先后逻辑进行时间线梳理。一个人负责算法部分，看了半天文献，实现了半天功能，累到吐血。虽然最终没得奖，但是收获颇丰。

<!-- more -->

## 梳理产品需求
### 灵感
灵感来源于生活，最近的热点事件经常发生反转。在这个信息大爆炸的时代，假如我们没有对一个事件进行每天的追踪，就很有可能导致跟不上事件的进度，无法对事件的起源、经过、反转有一个全局的视角。  
### 竞品
我们对一个名为“后续”的app惊醒了竞品分析，发现如下的问题：
1. 内容同质：本质只是内容聚合
2. 逻辑缺失：时间线仅是文章发布的时间线
3. 人工干预：事件线索由人工梳理
4. 本质问题：技术瓶颈
### 产品定位
定位：利用机器从海量文本中挖掘事件相关新闻并结合事件发生的先后逻辑进行时间线梳理的资讯类产品  
应用场景：在选定事件后对其进行追溯及跟踪  
优点
1. 在海量的信息中迅速为用户梳理出事件逻辑；
2. 智能追踪事件后续发展


## 设计技术架构
根据产品定位，我们拆分成四步子问题：
1. 有哪些新闻
2. 有哪些事件
3. 哪些新闻属于哪些事件
4. 事件中新闻的帅选和排序  

完成这个产品实际就是对这四个子问题分别给出尽量精确的答案，否则每个步骤的积累误差是很严重的。

## 探索与解决方案
下面让我们来解决这四个问题，技术方案只看了半天的文献，由于只有我一个人去回答这四个问题，所以以下解决方案是经过一定权衡的，不代表业界的正常方法。甚至也不能说是主流的解决方案，只能说是并带着问题脑补的四个子系统。

### 一、有哪些新闻
我们选取了搜狐娱乐频道一级二级优质账号发文，范围是从年初至今，共有87240篇。选取优质账号是为了使事件相关的文章内容尽可能优质；限定娱乐频道是为了让我们的想法在一个领域限定的语境下能work，同时娱乐圈的新闻有着高频的时间线，同时不那么严肃，不至于产生新闻事故。  
首先第一个想法是去做文章的摘要生成，有以下两点原因：  
```
一、是因为文本的内容特别多，所以做摘要之后能更好地统一文本的长度，方便之后的处理。  
二、使用文本摘要代表文章能加快之后的匹配速度。  
三、搜狐文章里生成的摘有长度限制，质量也不高，基本不可用。
```
下面来动手生成文本摘要：
1. 分词使用pkuseg分词工具（Xu Sun，2012）
2. 选用在微博训练集上训练的分词模型，对娱乐相关文本准确度更好
3. 用户词典选用明星姓名
4. 长文本摘要生成使用TextRank（mihalcea，2004）

### 二、有哪些事件
事件的抽取属于一个很难的问题，从文本中抽取信息

### 三、哪些新闻属于哪些事件

### 四、事件中新闻的筛选和排序

## 总结
人口和时间的劣势是一方面，技术难度也是一方面，评委的专业程度对我们更是致命打击。由于评委对该领域有深入的研究，对整个系统的瓶颈点抛出了各种灵魂拷问：  
1. 怎么处理bad case  
2. 查找事件的关联新闻时，怎么设置阈值
3. 事件中的新闻怎么进行排序

我们短时间内脑补的解决方案当然不能让深耕于此的评委满意，于是只能以仅仅跑通整个流程来作为我们最简单的目标。   
一个人一天的demo和一个真正落地的线上系统有着本质的差异，这是两种完全不同的状态，hackaton可以用很简单粗狂的模式进行开发，但是后者却不可能。感谢这一天时光，让一个迷茫的后端工程师对算法又重燃了兴趣。  
在马拉松当天，Keras的作者François Chollet恰巧发了一个推：
```
"90% of the time, when an engineer (or researcher) uses X to solve Y, it's a case of "I kind of know X" rather than "I have evidence that X is an appropriate solution in this case"
```
大致就是说大部分工程师只是手上有锤子，看见任何类似钉子的东西都想锤一下。假使我们的武器库不够丰富，能做的事情就慢慢出现了局限性。多做，多思考，多总结，要走的路还很长。

